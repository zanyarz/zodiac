Please feel free to contribute to this project, make it better, invetigate on various aspects of ZoDIAC and please cite our work if you use this project.
Furthermore, we highly encourage other researchers in the community to investigate the usefulness of our method in models that highly leverage self-attention
with least amount of changes inside the Transformer model and most changes in the parameter size and layer numbers.
